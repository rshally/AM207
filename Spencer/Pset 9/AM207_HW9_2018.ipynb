{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APMTH 207: Advanced Scientific Computing: \n",
    "## Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "## Homework 9\n",
    "**Harvard University**<br>\n",
    "**Spring 2018**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date: ** Saturday, April 7th, 2018 at 10:59am\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers as an iPython notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Homework is a continuation of Problem #1 from Homework 8.\n",
    "\n",
    "Your answers to Problem #1 from HW8 should  give you a idea of how one might create or select a model for a particular application and your answers will help you with formalizing the model in this Homework, which is much more technically involved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #1: Modeling Your Understanding\n",
    "\n",
    "In the dataset \"reviews_processed.csv\", you'll find a database of Yelp reviews for a number of restaurants. These reviews have already been processed and transformed by someone who has completed the (pre) modeling process described in Problem #1. That is, imagine the dataset in \"reviews_processed.csv\" is the result of feeding the raw Yelp reviews through the pipeline someone built for Problem #1.\n",
    "\n",
    "The following is a full list of columns in the dataset and their meanings:\n",
    "\n",
    "I. Relevant to Part A and B:\n",
    "\n",
    "  1. \"review_id\" - the unique identifier for each Yelp review\n",
    "  2. \"topic\" - the subject addressed by the review (0 stands for food and 1 stands for service)\n",
    "  3. \"rid\" - the unique identifier for each restaurant\n",
    "  4. \"count\" - the number of sentences in a particular review on a particular topic\n",
    "  5. \"mean\" - the probability of a sentence in a particular review on a particular topic being positive, averaged over total number of sentences in the review related to that topic.\n",
    "  6. \"var\" - the variance of the probability of a sentence in a particular review on a particular topic being positive, taken over all sentences in the review related to that topic.\n",
    "\n",
    "II. Relevant (possibly) to Extra Credit:\n",
    "\n",
    "  1. \"uavg\" - the average star rating given by a particular reviewer (taken across all their reviews)\n",
    "  2. \"stars\" - the number of stars given in a particular review\n",
    "  3. \"max\" - the max probability of a sentence in a particular review on a particular topic being positive\n",
    "  4. \"min\" - the min probability of a sentence in a particular review on a particular topic being positive\n",
    "\n",
    "The following schema illustrates the model of the raw data that is used to generate \"reviews_processed.csv\":\n",
    "<img src=\"restuarant_model.pdf\">\n",
    "\n",
    "***Warning:*** *this is a \"real\" data science problem in the sense that the dataset in \"reviews_processed.csv\" is large. We understand that a number of you have limited computing resources, so you are encouraged but not required to use the entire dataset. If you wish you may use 10 restaurants from the dataset, as long as your choice of 10 contains a couple of restaurants with a large number of reviews and a couple with a small number of reviews.*\n",
    "\n",
    "### Part A: Modeling\n",
    "\n",
    "When the value in \"count\" is low, the \"mean\" value can be very skewed.\n",
    "\n",
    "Following the [SAT prep school example discussed in lab](https://am207.github.io/2018spring/wiki/gelmanschoolstheory.html) (and using your answers for HW 8 Problem #1), set up a Bayesian model(that is, write functions encapsulating the pymc3 code) for a reviewer $j$'s opinion of restaurant $k$'s food and service, separately. That is, you will have a model for each restaurant and each aspect (food and serivce). For restaurant $k$, you will have a model for $\\{\\theta_{jk}^{\\text{food}}\\}$ and one for $\\{\\theta_{jk}^{\\text{service}}\\}$, where $\\theta_{jk}$ is the positivity of the opinion of the $j$-th reviewer regarding the $k$-th restaurant. \n",
    "\n",
    "**Hint:** what quantity in our data naturally corresponds to $\\bar{y}_j$'s in the prep school example? How would you calculate the parameter $\\sigma_j^2$ in the distribution of $\\bar{y}_j$ (note that, contrary to the school example, $\\sigma_j^2$ is not provided explictly in the restaurant data)?\n",
    "\n",
    "### Part B: Analysis for Each restaurant\n",
    "\n",
    "Use your model to produce estimates for $\\theta_{jk}$'s. Pick a few restaurants, for each aspect (\"food\" and \"service\") of each restaurant, plot your estimates for the $\\theta$'s against the values in the \"mean\" column (corresponding to this restaurant). \n",
    "\n",
    "For the same restaurants, for each aspect, generate shrinkage plots and probability shrinkage plots as follows:\n",
    "\n",
    "**Shrinkage plot for a restaurant, topic**:\n",
    "\n",
    "The aim for this plot is to see the shrinkage from sample means (error bars generated from standard error) to $\\theta_{jk}$'s (error bars generated from theta variance).  \n",
    "\n",
    "The sample means of reviews are plotted at $y=0$ and the posterior means ($\\theta_{ik}$) are plotted at $y=1$. For each review connect the sample mean to the posterior mean with a line.  Show error bars on the sample mean points using standard error and on the ($\\theta_{jk}$) points using variance.\n",
    "\n",
    "**Probability Shrinkage plot for a restaurant, topic**:\n",
    "\n",
    "The aim for this plot is to see the shrinkage from the classification probabilities from the sample means of reviews to the classification probabilities of $\\theta_{jk}$'s.  The classification probabilities are calculated from the gaussian at the given mean and variance. The sample means and standard error are fed into the gaussian to generate one set of classification probabilities.  The $\\theta_{jk}$ estimates and variances are fed into the gaussian to generate the other set of variances.\n",
    "\n",
    "The y values are the classification probability (calculated as 1-cdf) using the normal distribution at a given mean and variance.\n",
    "\n",
    "The sample means of reviews are plotted with $y$'s obtained by using the sample means as the means in the normal above, with line segments (error bars) representing the standard error. \n",
    "\n",
    "The posterior means ($\\theta_{jk}$) are plotted with $y$'s obtained using the posterior means (thetas) in the gaussian above, and variances on the thetas with line segments (error bars) representing the variances on the $\\theta_{jk}$'s.\n",
    "\n",
    "We've provided you some code to generate a shrinkage plot and a probability shrinkage plot is included in this notebook, but feel free to implement your own. The code should also help elucidate the text above.\n",
    "\n",
    "Use these plots to discuss the statistical benefits of modeling each reviewer's opinion using your model from Part A, rather than approximating the reviewer opinion with the value in \"mean\".\n",
    "\n",
    "Example of a shrinkage plot:\n",
    "<img src=\"shrinkage.png\">\n",
    "\n",
    "Example of a probability shrinkage plot:\n",
    "<img src=\"shrinkage_prob.png\">\n",
    "\n",
    "### Part C: Analysis Across Restaurants\n",
    "\n",
    "Aggregate, in a simple but reasonable way, the reviewer's opinions given a pair of overall scores for each restaurant -- one for food and one for service. Rank the restaurants by food score and then by service score. Discuss the statistical weakness of ranking by these scores.\n",
    "\n",
    "(**Hint:** what is statistically problematic about the way you aggregated the reviews of each restaurant to produce an overall food or service score? You've seen this question addressed a number of times in previous homeworks. This is also the same problem with summarizing a reviewer's opinion on a restaurants service and food based on what they write.)\n",
    "\n",
    "### Extra Credit:\n",
    "\n",
    "1. Propose a model addressing the weakness of your approach in Part C for the overall quality of food and service for each restaurant given the $\\theta$'s. Combine your model for the overall quality with your model for the $\\theta$'s. \n",
    "2. Implement and use this combined model to estimate the overall quality of food and service for each restaurant.\n",
    "\n",
    "(Its perfectly ok to just propose and not implement, you'll just get less credit. But please atleast try part 1!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Use 1-cdf at 0.5 to model the probability of having positive sentiment\n",
    "# it basically tells you the area under the gaussian after 0.5 (we'll assume \n",
    "# positive sentiment based on the usual probability > 0.5 criterion)\n",
    "\n",
    "prob = lambda mu, vari: .5 * (1 - erf((0.5- mu) / np.sqrt(2 * vari)))\n",
    "\n",
    "# fix a restaurant and an aspect (food or service)\n",
    "# \"means\" is the array of values in the \"mean\" column for the restaurant and the aspect \n",
    "#         in the dataset\n",
    "# \"thetas\" is the array of values representing your estimate of the opinions of reviewers \n",
    "#          regarding this aspect of this particular restaurant\n",
    "# \"theta_vars\" is the array of values of the varaiances of the thetas\n",
    "# \"counts\" is the array of values in the \"count\" column for the restaurant and the aspect \n",
    "#.         in the dataset\n",
    "# FEEL FREE TO RE-IMPLEMENT THESE\n",
    "\n",
    "def shrinkage_plot(means, thetas, mean_vars, theta_vars, counts):\n",
    "    \"\"\"\n",
    "    a plot that shows how review means (plotted at y=0) shrink to\n",
    "    review $theta$s, plotted at y=1\n",
    "    \"\"\"\n",
    "    data = zip(means, thetas, mean_vars / counts, theta_vars, counts)   \n",
    "    palette = itertools.cycle(sns.color_palette())\n",
    "    with sns.axes_style('white'):\n",
    "        for m,t, me, te, c in data: # mean, theta, mean errir, theta error, count\n",
    "            color=next(palette)\n",
    "            # add some jitter to y values to separate them\n",
    "            noise=0.04*np.random.randn()\n",
    "            noise2=0.04*np.random.randn()\n",
    "            if me==0:\n",
    "                me = 4\n",
    "            # plot shrinkage line from mean, 0 to\n",
    "            # theta, 1. Also plot error bars\n",
    "            plt.plot([m,t],[noise,1+noise2],'o-', color=color, lw=1)\n",
    "            plt.errorbar([m,t],[noise,1+noise2], xerr=[np.sqrt(me), np.sqrt(te)], color=color,  lw=1)\n",
    "        plt.yticks([])\n",
    "        plt.xlim([0,1])\n",
    "        sns.despine(offset=-2, trim=True, left=True)\n",
    "    return plt.gca()\n",
    "\n",
    "def prob_shrinkage_plot(means, thetas, theta_vars, counts):\n",
    "    \"\"\"\n",
    "    a plot that shows how review means (plotted at y=prob(mean)) shrink to\n",
    "    review $theta$s, plotted at y=prob(theta)\n",
    "    \"\"\"\n",
    "    data = zip(means, thetas, theta_vars / counts, theta_vars, counts)\n",
    "    palette = itertools.cycle(sns.color_palette())\n",
    "    with sns.axes_style('white'):\n",
    "        for m,t, me, te, c in data: # mean, theta, mean errir, theta error, count\n",
    "            color = next(palette)\n",
    "            # add some jitter to y values to separate them\n",
    "            noise = 0.001 * np.random.randn()\n",
    "            noise2 = 0.001 * np.random.randn()\n",
    "            if me == 0: #make mean error super large if estimated as 0 due to count=1\n",
    "                me = 4\n",
    "            p = prob(m, me)\n",
    "            peb = prob(t, te)\n",
    "            # plot shrinkage line from mean, prob-based_on-mean to\n",
    "            # theta, prob-based_on-theta. Also plot error bars\n",
    "            plt.plot([m, t],[p, peb],'o-', color=color, lw=1)\n",
    "            plt.errorbar([m, t],[p + noise, peb + noise2], xerr=[np.sqrt(me), np.sqrt(te)], color=color, lw=1)\n",
    "        ax = plt.gca()\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1.05])\n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
